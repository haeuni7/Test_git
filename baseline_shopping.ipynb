{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haeuni7/Test_git/blob/main/baseline_shopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41196da1-2198-44a5-b93f-9bb8335bcf15"
      },
      "source": [
        "# 쇼핑 고객 상담 대화 문장 의도 태깅\n",
        "\n",
        "- 2차 모의경진대회(22.11.28 ~ 22.12.25)\n",
        "- Text Classification 과제"
      ],
      "id": "41196da1-2198-44a5-b93f-9bb8335bcf15"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pgSg-Imnq3x"
      },
      "source": [
        "## 디렉터리 구조\n",
        "```\n",
        "$ Shopping/\n",
        "├── DATA/\n",
        "│    ├── train/\n",
        "│    │    ├── texts/\n",
        "│    │    │    ├── shopping1_0001.txt\n",
        "│    │    │    ├── ...\n",
        "│    │    │    └── shopping7_2536.txt\n",
        "│    │    └── labels/\n",
        "│    │          ├── shopping1_0001.json\n",
        "│    │          ├── ...\n",
        "│    │          └── shopping7_2536.json\n",
        "│    ├── test/\n",
        "│    │    └── texts/\n",
        "│    │          ├── test_0001.txt\n",
        "│    │          ├── ...\n",
        "│    │          └── test_1456.txt\n",
        "│    └── sample_submission.csv\n",
        "│\n",
        "└── baseline/\n",
        "      ├── config/\n",
        "      │    ├── train.yaml\n",
        "      │    └── predict.yaml\n",
        "      │── modules/\n",
        "      │    ├── earlystopper.py\n",
        "      │    ├── losses.py\n",
        "      │    ├── recorders.py\n",
        "      │    └── utils.py\n",
        "      ├── results/\n",
        "      │    └── train/\n",
        "      ├── wandb/ # wandb 최초 사용 후 생성\n",
        "      ├── baseline_shopping.ipynb\n",
        "      └── submission.csv (코드 실행 후 생성되는 추론 파일)\n",
        "\n",
        "```\n",
        "    - config : 학습/추론에 필요한 파라미터 등을 기록하는 yaml 파일\n",
        "    - modules\n",
        "        - earlystopper.py : loss가 특정 에폭 이상 개선되지 않을 경우 학습을 멈춤\n",
        "        - losses.py : config에서 지정한 loss function을 리턴\n",
        "        - recorders.py : log, learning curve, best model.pt 등을 기록\n",
        "        - utils.py : 여러 확장자 파일을 불러오거나 여러 확장자로 저장하는 등의 함수\n",
        "    - results\n",
        "      - train/ : 학습 log, 추론 log를 기록하는 디렉토리\n",
        "    - baseline_shopping.ipynb : 전처리부터 학습, 추론까지 수행할 코드 \n",
        "\n",
        "## 노트북 실행 요령\n",
        "- 해당 베이스라인 코드는 [Wandb](https://wandb.ai/site) 를 활용한 실험 관리가 가능합니다.\n",
        "- 해당 베이스라인 코드 실행 전 `config/train.yaml`을 수정하세요.\n",
        "- 해당 베이스라인 코드의 추론 실행 전 `config/predict.yaml`을 수정하세요.\n",
        "- 학습 결과는 `results/train/train_serial` 에 저장되며, wandb를 통해 학습 그래프를 확인하실 수 있습니다."
      ],
      "id": "8pgSg-Imnq3x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v-ms2L0KK0M"
      },
      "source": [
        "#0. 사전 준비"
      ],
      "id": "9v-ms2L0KK0M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa9Mx1ZMKPkv"
      },
      "source": [
        "### 구글 드라이브 마운트"
      ],
      "id": "wa9Mx1ZMKPkv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wdxa3N8NO3A",
        "outputId": "247fe24b-3a2f-4444-ba7d-84f4ccfa9640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 구글 Colaboratory 를 사용하기 위해 구글 계정으로 로그인합니다. \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "4wdxa3N8NO3A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MEzQP3GPrDd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Shopping/')"
      ],
      "id": "-MEzQP3GPrDd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f186a6a3-e5e4-41a4-bb3e-89c64aa01910"
      },
      "source": [
        "### 라이브러리 설치"
      ],
      "id": "f186a6a3-e5e4-41a4-bb3e-89c64aa01910"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "42f536b6-3347-4252-a704-607de720c21e",
        "outputId": "b74a364e-9f03-4a91-cc21-31a0103410d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 38.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting datasets>=2.0.0\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 44.9 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.1 evaluate-0.3.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf) (6.0)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 30.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=ba59477abea1f910add8a7014868bc7b288a62ffbe634a60125ea021a41d68a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.2.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.6-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.6 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 73.1 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.23.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 56.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 71.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 68.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 65.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 48.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 70.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 66.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 65.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 70.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 59.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 57.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 53.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 67.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 66.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=ee8e0be19a837cf3ae9cbbeccaabb288a97d98f2509955dda92c34344f93d709\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.6\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install omegaconf\n",
        "!pip install wandb"
      ],
      "id": "42f536b6-3347-4252-a704-607de720c21e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55fee252-995d-448b-93d5-6ca72a4f68f3"
      },
      "source": [
        " # 1. Import"
      ],
      "id": "55fee252-995d-448b-93d5-6ca72a4f68f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48569888-879e-4e14-8220-454dc06b73f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import wandb\n",
        "import shutil\n",
        "import random\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "from sklearn.metrics import f1_score\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils import *\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import logging, get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup, get_constant_schedule_with_warmup\n",
        "from transformers import ( \n",
        "    BertConfig,\n",
        "    ElectraConfig\n",
        ")\n",
        "\n",
        "\n",
        "# 실험에 사용할 모델 라이브러리 추가\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertTokenizerFast,\n",
        "    AutoTokenizer,\n",
        "    ElectraTokenizer,\n",
        "    AlbertTokenizer,\n",
        "    RobertaTokenizerFast\n",
        ")\n",
        "from transformers import (\n",
        "    BertModel,\n",
        "    AutoModel, \n",
        "    ElectraForSequenceClassification,\n",
        "    BertForSequenceClassification,\n",
        "    AlbertForSequenceClassification,\n",
        "    RobertaForSequenceClassification,\n",
        "    TextClassificationPipeline\n",
        ")"
      ],
      "id": "48569888-879e-4e14-8220-454dc06b73f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3423814c-c555-4992-8f37-4886afa8fe86"
      },
      "source": [
        "# 2. 실험 세팅 \n",
        "### Train Configuration"
      ],
      "id": "3423814c-c555-4992-8f37-4886afa8fe86"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "059bba81-155c-4fe8-af14-1ee8ee8d94f1",
        "outputId": "7597447f-f374-4f18-cf7a-7860ca1abfc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_DIR : /content/drive/MyDrive/Shopping\n"
          ]
        }
      ],
      "source": [
        "# Project directory\n",
        "PROJECT_DIR = os.getcwd()\n",
        "print('PROJECT_DIR :',PROJECT_DIR)\n",
        "\n",
        "# Load train config\n",
        "## !!! config 수정할때마다 이 셀을 다시 실행하세요 !!!\n",
        "config_path = os.path.join(PROJECT_DIR, 'baseline', 'config', 'train.yaml')\n",
        "config = OmegaConf.load(config_path)"
      ],
      "id": "059bba81-155c-4fe8-af14-1ee8ee8d94f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc69bd47-35c2-4119-aefd-923b34f98426"
      },
      "source": [
        "### 실험 기록 및 경로 설정"
      ],
      "id": "fc69bd47-35c2-4119-aefd-923b34f98426"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6655c514-58ef-4c7e-8ed9-9e8596adc003",
        "outputId": "aad43255-a25e-4318-a3f2-f37f41fea68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results will be found here :  /content/drive/MyDrive/Shopping/results/train/20221019_180402\n",
            "DATA_DIR : /content/drive/MyDrive/Shopping/DATA\n",
            "TRAIN_DIR : /content/drive/MyDrive/Shopping/DATA/train\n",
            "TEST_DIR : /content/drive/MyDrive/Shopping/DATA/test\n",
            "SAMPLE_DIR : /content/drive/MyDrive/Shopping/DATA/sample_submission.csv\n"
          ]
        }
      ],
      "source": [
        "# Train Serial\n",
        "kst = timezone(timedelta(hours=9))\n",
        "train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "# Recorder directory\n",
        "if config.train.resume==None:\n",
        "    RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n",
        "else:\n",
        "    RECORDER_DIR = os.path.join(PROJECT_DIR, config.train.resume_weight_dir)\n",
        "    \n",
        "os.makedirs(RECORDER_DIR, exist_ok=True)\n",
        "print(\"Results will be found here : \", RECORDER_DIR)\n",
        "\n",
        "# Data Directory\n",
        "DATA_DIR = Path(config.train.dataset_path)\n",
        "TRAIN_DIR = DATA_DIR/'train/'\n",
        "TEST_DIR = DATA_DIR/'test/'\n",
        "SAMPLE_DIR = os.path.join(DATA_DIR,'sample_submission.csv')\n",
        "\n",
        "print('DATA_DIR :',DATA_DIR)\n",
        "print('TRAIN_DIR :',TRAIN_DIR)\n",
        "print('TEST_DIR :',TEST_DIR)\n",
        "print('SAMPLE_DIR :',SAMPLE_DIR)"
      ],
      "id": "6655c514-58ef-4c7e-8ed9-9e8596adc003"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64f73a37-0f4e-4ff8-a9df-bf580e894f42"
      },
      "source": [
        "### Seed 고정 및 GPU 지정"
      ],
      "id": "64f73a37-0f4e-4ff8-a9df-bf580e894f42"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48df682e-bd21-4a51-833f-1115166d8bc1",
        "outputId": "1846e688-fe9a-4639-fcb9-59a34c0e9a48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Seed 설정\n",
        "random.seed(config.train.seed)\n",
        "np.random.seed(config.train.seed)\n",
        "torch.manual_seed(config.train.seed)\n",
        "torch.cuda.manual_seed_all(config.train.seed)\n",
        "\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "id": "48df682e-bd21-4a51-833f-1115166d8bc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79b2fe59-0197-44ed-8ba7-68c988b2747f"
      },
      "source": [
        "### Set logger"
      ],
      "id": "79b2fe59-0197-44ed-8ba7-68c988b2747f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6de5e92-2781-487a-b2b9-1f71665d9d0f",
        "outputId": "24cbf4c6-cdf4-4486-a93a-eb2f85de960e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:train:Set Logger /content/drive/MyDrive/Shopping/results/train/20221019_180402\n",
            "INFO:train:train:\n",
            "  dataset_path: /content/drive/MyDrive/Shopping/DATA\n",
            "  num_classes: 14\n",
            "  max_seq_len: 128\n",
            "  train_batch_size: 32\n",
            "  eval_batch_size: 32\n",
            "  num_epochs: 1\n",
            "  metric: f1\n",
            "  seed: 777\n",
            "  early_stopping_patience: 5\n",
            "  resume: true\n",
            "  resume_weight_dir: results/train/20221019_180402\n",
            "  save_strategy: epoch\n",
            "  save_steps: 100\n",
            "  eval_steps: 500\n",
            "  evaluation_strategy: epoch\n",
            "  fp16: true\n",
            "  num_workers: 1\n",
            "  use_cuda: true\n",
            "  gpus: '1'\n",
            "  optimizer: adam\n",
            "  adam_epsilon: 1.0e-08\n",
            "  warmup_proportion: 0.04\n",
            "  learning_rate: 5.0e-05\n",
            "  weight_decay: 0.01\n",
            "  wandb: true\n",
            "  logging_strategy: epoch\n",
            "  logging_steps: 200\n",
            "model:\n",
            "  pretrained_model: klue/roberta-base\n",
            "  architecture: RobertaForSequenceClassification\n",
            "  tokenizer_class: BertTokenizer\n",
            "\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/drive/MyDrive/Shopping/baseline')\n",
        "from modules.utils import get_logger\n",
        "\n",
        "logger = get_logger(name='train', dir_=RECORDER_DIR, stream=False)\n",
        "logger.info(f\"Set Logger {RECORDER_DIR}\")\n",
        "logger.info(OmegaConf.to_yaml(config))"
      ],
      "id": "d6de5e92-2781-487a-b2b9-1f71665d9d0f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899bc951-851a-43ea-95e9-49fa4e2fa0c9"
      },
      "source": [
        "# 3. EDA 및 데이터 전처리\n",
        "### DataFrame으로 시각화"
      ],
      "id": "899bc951-851a-43ea-95e9-49fa4e2fa0c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "551d2840-11f9-4e27-adbe-4b998bb9c508"
      },
      "outputs": [],
      "source": [
        "def make_df(data_dir:Path, test=False):\n",
        "    sentence_id=[]     # 파일명 + .txt + 텍스트 내에서 문장 순서\n",
        "    speaker = []       # 화자\n",
        "    text = []          # text\n",
        "    speechAct = []     # 문장이 어떤 내용인지 말해주는 label값\n",
        "    \n",
        "    for directory in data_dir.iterdir():\n",
        "        for file in directory.iterdir():\n",
        "            if 'checkpoint' in str(file): continue\n",
        "            if test ==False:\n",
        "                try:\n",
        "                    label = json.load(open(file))\n",
        "                except:\n",
        "                    continue\n",
        "                lines = label['info'][0]['annotations']['lines']\n",
        "                for i, l in enumerate(lines):\n",
        "                    sentence_id.append(file.stem+'.txt-'+str(i)) # 문장 id\n",
        "                    speaker.append(l['text'].split('.')[0]) # 화자 넣기\n",
        "                    text.append(l['text'].split('.')[-1]) # 화자 구분 빼기\n",
        "                    speechAct.append(l['speechAct'])\n",
        "            elif file.match(\"*.txt\"):\n",
        "                try:\n",
        "                    with open(file, \"r\") as f:\n",
        "                        lines = f.read().splitlines()\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "                for i, l in enumerate(lines):\n",
        "                    sentence_id.append(file.stem+'.txt-'+str(i))\n",
        "                    speaker.append(l.split('.')[0]) # 화자 넣기\n",
        "                    text.append(l.split('.')[-1]) # 화자 구분 빼기\n",
        "    if test==False:\n",
        "        df = pd.DataFrame({'sentence_id': sentence_id, 'speaker':speaker,'text': text, 'speechAct':speechAct})\n",
        "    else:\n",
        "        df = pd.DataFrame({'sentence_id': sentence_id, 'speaker':speaker,'text': text})\n",
        "\n",
        "    return df"
      ],
      "id": "551d2840-11f9-4e27-adbe-4b998bb9c508"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23aa4a5d-fa56-4f1f-a00a-1a14dd6b2e49"
      },
      "outputs": [],
      "source": [
        "train_df = make_df(TRAIN_DIR)"
      ],
      "id": "23aa4a5d-fa56-4f1f-a00a-1a14dd6b2e49"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8b5d7d3c-f493-4f54-9e8c-9be9b9ae49d5",
        "outputId": "e827c276-549a-48df-fc80-fba491fbca93"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cbb37ef2-0a9d-4d96-ac81-a23f054fcdf7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "      <th>speechAct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>shopping1_2424.txt-0</td>\n",
              "      <td>A</td>\n",
              "      <td>반갑습니다 상담사 #@이름#입니다</td>\n",
              "      <td>인사하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>shopping1_2424.txt-1</td>\n",
              "      <td>B</td>\n",
              "      <td>세탁기 산 지가 아직 일 년이 안 됐는데 고장이 났어요</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>shopping1_2424.txt-2</td>\n",
              "      <td>A</td>\n",
              "      <td>고객님 세탁기의 종류는 무엇인가요</td>\n",
              "      <td>질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>shopping1_2424.txt-3</td>\n",
              "      <td>B</td>\n",
              "      <td>지금 일반 통돌이 쓰고 있어요</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shopping1_2424.txt-4</td>\n",
              "      <td>A</td>\n",
              "      <td>어떤 것이 고장이 났나요</td>\n",
              "      <td>질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189778</th>\n",
              "      <td>shopping3_1565.txt-6</td>\n",
              "      <td>B</td>\n",
              "      <td>뭐 따로 해야 할 절차가 있을까요</td>\n",
              "      <td>질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189779</th>\n",
              "      <td>shopping3_1565.txt-7</td>\n",
              "      <td>A</td>\n",
              "      <td>이 기능을 이용하기 위해서는요</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189780</th>\n",
              "      <td>shopping3_1565.txt-8</td>\n",
              "      <td>A</td>\n",
              "      <td>사용할 계좌 인증 및 자동이체 출금 동의 절차를 완료해야 합니다</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189781</th>\n",
              "      <td>shopping3_1565.txt-9</td>\n",
              "      <td>B</td>\n",
              "      <td>네 그렇군요 알겠습니다</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189782</th>\n",
              "      <td>shopping3_1565.txt-10</td>\n",
              "      <td>A</td>\n",
              "      <td>네 답변이 도움이 되었기를 바랍니다 감사합니다</td>\n",
              "      <td>감사하기</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>189783 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbb37ef2-0a9d-4d96-ac81-a23f054fcdf7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbb37ef2-0a9d-4d96-ac81-a23f054fcdf7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbb37ef2-0a9d-4d96-ac81-a23f054fcdf7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  sentence_id speaker                                 text  \\\n",
              "0        shopping1_2424.txt-0       A                   반갑습니다 상담사 #@이름#입니다   \n",
              "1        shopping1_2424.txt-1       B       세탁기 산 지가 아직 일 년이 안 됐는데 고장이 났어요   \n",
              "2        shopping1_2424.txt-2       A                   고객님 세탁기의 종류는 무엇인가요   \n",
              "3        shopping1_2424.txt-3       B                     지금 일반 통돌이 쓰고 있어요   \n",
              "4        shopping1_2424.txt-4       A                        어떤 것이 고장이 났나요   \n",
              "...                       ...     ...                                  ...   \n",
              "189778   shopping3_1565.txt-6       B                   뭐 따로 해야 할 절차가 있을까요   \n",
              "189779   shopping3_1565.txt-7       A                     이 기능을 이용하기 위해서는요   \n",
              "189780   shopping3_1565.txt-8       A  사용할 계좌 인증 및 자동이체 출금 동의 절차를 완료해야 합니다   \n",
              "189781   shopping3_1565.txt-9       B                         네 그렇군요 알겠습니다   \n",
              "189782  shopping3_1565.txt-10       A            네 답변이 도움이 되었기를 바랍니다 감사합니다   \n",
              "\n",
              "       speechAct  \n",
              "0           인사하기  \n",
              "1           진술하기  \n",
              "2           질문하기  \n",
              "3           진술하기  \n",
              "4           질문하기  \n",
              "...          ...  \n",
              "189778      질문하기  \n",
              "189779      진술하기  \n",
              "189780      진술하기  \n",
              "189781      진술하기  \n",
              "189782      감사하기  \n",
              "\n",
              "[189783 rows x 4 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ],
      "id": "8b5d7d3c-f493-4f54-9e8c-9be9b9ae49d5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfe1e61a-cb95-49a3-a1ee-0415d5e82bbb"
      },
      "outputs": [],
      "source": [
        "# 라벨을 인코딩할 딕셔너리 (학습에 사용)\n",
        "label2encoding = {Act: ind for ind, Act in enumerate(train_df['speechAct'].unique())}\n",
        "# 인코딩된 라벨을 디코딩할 딕셔너리 (추론에 사용)\n",
        "encoding2label = {idx: Act for idx, Act in enumerate(train_df['speechAct'].unique())}"
      ],
      "id": "bfe1e61a-cb95-49a3-a1ee-0415d5e82bbb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e1a4da2-7464-4564-8df9-38de6e849360",
        "outputId": "224ceb89-5d5a-4d27-a74a-0f3773267b7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Series([], Name: text, dtype: object)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 길이가 128이 넘는 코멘트가 있는지 확인\n",
        "train_df['text'][train_df['text'].str.len()>config.train.max_seq_len]"
      ],
      "id": "1e1a4da2-7464-4564-8df9-38de6e849360"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce4062a-7030-4a06-9ec1-985a9e7bd49e"
      },
      "source": [
        "### Tokenizer"
      ],
      "id": "7ce4062a-7030-4a06-9ec1-985a9e7bd49e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ad836f0-27b4-42ac-bb38-99352a077def",
        "outputId": "cba894ca-db46-43ba-bcd2-df9449322ca2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1979c110479f46a7a354bf1fb4e95451",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "251f4dbc924a4cc8bda4053e7a04057a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6f6787da8cc485d841eb087d1da30c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/375 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# config.json 에서 지정 이름별로 가져올 라이브러리 지정\n",
        "\n",
        "TOKENIZER_CLASSES = {\n",
        "    \"BertTokenizer\": BertTokenizer,\n",
        "    \"BertTokenizerFast\": BertTokenizerFast,\n",
        "    \"AutoTokenizer\": AutoTokenizer,\n",
        "    \"ElectraTokenizer\": ElectraTokenizer,\n",
        "    \"AlbertTokenizer\": AlbertTokenizer,\n",
        "    \"RobertaTokenizerFast\" : RobertaTokenizerFast\n",
        "}\n",
        "TOKENIZER = TOKENIZER_CLASSES[config.model.tokenizer_class].from_pretrained(config.model.pretrained_model)"
      ],
      "id": "7ad836f0-27b4-42ac-bb38-99352a077def"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bfe68a6-f3bc-4182-8666-43588fa12bc1",
        "outputId": "61600a00-e387-442f-c5eb-21b10e4fe056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [0, 9927, 2219, 3606, 4981, 2063, 7, 36, 3934, 7, 3714, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "[0, 9927, 2219, 3606, 4981, 2063, 7, 36, 3934, 7, 3714, 2] \n",
            "\n",
            "['반갑', '##습', '##니다', '상담', '##사', '#', '@', '이름', '#', '입니다'] \n",
            "\n",
            "[9927, 2219, 3606, 4981, 2063, 7, 36, 3934, 7, 3714]\n"
          ]
        }
      ],
      "source": [
        "# Tokenizer 예시\n",
        "comment_ex = train_df['text'][0]\n",
        "print(TOKENIZER(comment_ex))\n",
        "print(TOKENIZER.encode(comment_ex),\"\\n\")\n",
        "\n",
        "# 토큰으로 나누기\n",
        "print(TOKENIZER.tokenize(comment_ex),\"\\n\")\n",
        "\n",
        "# 토큰 id로 매핑하기\n",
        "print(TOKENIZER.convert_tokens_to_ids(TOKENIZER.tokenize(comment_ex)))"
      ],
      "id": "2bfe68a6-f3bc-4182-8666-43588fa12bc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d1f4263-b34c-4d32-9e45-6243bafb018c"
      },
      "source": [
        "# 4. Dataset"
      ],
      "id": "3d1f4263-b34c-4d32-9e45-6243bafb018c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIiEaoZLN-qY"
      },
      "source": [
        "### CustomDataset 클래스 정의"
      ],
      "id": "dIiEaoZLN-qY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00f35f69-d09c-4931-bb2a-298ced956dd3"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):  # 데이터를 input으로 변환해주는 Dataset 클래스를 상속한 후 커스터마이징\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_seq_len, mode = 'train'):  # Dataset 클래스는 기본적으로 __init__, __len__, __getitem__를 정의해 주어야 한다\n",
        "\n",
        "        self.data = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.mode = mode\n",
        "        self.speakers = self.data['speaker'].tolist()\n",
        "        self.texts = self.data['text'].tolist()\n",
        "        \n",
        "        if self.mode!='test':\n",
        "            try: \n",
        "                self.labels = df['speechAct'].tolist()\n",
        "            except:\n",
        "                assert False, 'CustomDataset Error : \\'label\\' column does not exist in the dataframe'\n",
        "     \n",
        "    def __len__(self):  # index를 통해 input을 순차적으로 읽어오기 위해서는 데이터의 길이가 먼저 확인되어야 한다. __len__ 함수는 input의 길이를 반환해주는 함수\n",
        "        return len(self.data)\n",
        "                \n",
        "\n",
        "    def __getitem__(self, idx):  # input의 길이가 확인되면 index를 통해 데이터를 불러올 수 있다. __getitem__ 함수는 index에 해당하는 input 데이터를 반환해주는 함수\n",
        "        \"\"\"\n",
        "        전체 데이터에서 특정 인덱스 (idx)에 해당하는 기사제목과 댓글 내용을 \n",
        "        토크나이즈한 data('input_ids', 'attention_mask','token_type_ids')의 딕셔너리 형태로 불러옴\n",
        "        \"\"\"\n",
        "        tokenized_text = self.tokenizer(self.texts[idx],\n",
        "                             padding= 'max_length',\n",
        "                             max_length=self.max_seq_len,\n",
        "                             truncation=True,\n",
        "                             return_token_type_ids=True,\n",
        "                             return_attention_mask=True,\n",
        "                             return_tensors = \"pt\")\n",
        "\n",
        "        if self.mode=='test':\n",
        "            data = {'input_ids': tokenized_text['input_ids'].squeeze(0).long(),\n",
        "                   'attention_mask': tokenized_text['attention_mask'].squeeze(0).long(),\n",
        "                   'token_type_ids': tokenized_text['token_type_ids'].squeeze(0).long()\n",
        "                    }\n",
        "        else:\n",
        "            data = {'input_ids': tokenized_text['input_ids'].squeeze(0).long(),\n",
        "                   'attention_mask': tokenized_text['attention_mask'].squeeze(0).long(),\n",
        "                   'token_type_ids': tokenized_text['token_type_ids'].squeeze(0).long(),\n",
        "                    'labels': label2encoding[self.labels[idx]]\n",
        "                    }\n",
        "\n",
        "\n",
        "        return data"
      ],
      "id": "00f35f69-d09c-4931-bb2a-298ced956dd3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3522ede-dcec-4a26-8cc1-b7e03ad5faf9"
      },
      "source": [
        "### Train, Validation set 나누기"
      ],
      "id": "d3522ede-dcec-4a26-8cc1-b7e03ad5faf9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb9fe7d4-95b8-4828-89f0-26a324fc1cab",
        "outputId": "68881a5f-05e9-4e2e-8743-577f301bc83e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset:  151826\n",
            "Validation dataset:  37957\n"
          ]
        }
      ],
      "source": [
        "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=config.train.seed)\n",
        "\n",
        "train_dataset = CustomDataset(train_data, TOKENIZER, config.train.max_seq_len, 'train')\n",
        "val_dataset = CustomDataset(val_data, TOKENIZER, config.train.max_seq_len, 'validation')\n",
        "\n",
        "print(\"Train dataset: \", len(train_dataset))\n",
        "print(\"Validation dataset: \", len(val_dataset))"
      ],
      "id": "cb9fe7d4-95b8-4828-89f0-26a324fc1cab"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abca2710-8f81-42f8-aeaf-6d6ea8b56dce"
      },
      "source": [
        "### DataLoader"
      ],
      "id": "abca2710-8f81-42f8-aeaf-6d6ea8b56dce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9a9ae26-30c4-4d50-a9df-916de91f5b69"
      },
      "outputs": [],
      "source": [
        "# torch.utils.data.DataLoader : input을 배치 단위로 리턴해주는 기능\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                                batch_size=config.train.train_batch_size,\n",
        "                                num_workers=config.train.num_workers, \n",
        "                                shuffle=True,\n",
        "                                pin_memory=True,\n",
        "                                drop_last=False)\n",
        "\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=config.train.eval_batch_size,\n",
        "                            num_workers=config.train.num_workers, \n",
        "                            shuffle=False,\n",
        "                            pin_memory=True,\n",
        "                            drop_last=False)\n"
      ],
      "id": "a9a9ae26-30c4-4d50-a9df-916de91f5b69"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f382b7f-3e20-4d01-97bd-4370b5326610"
      },
      "source": [
        "# 5. 모델 선언"
      ],
      "id": "6f382b7f-3e20-4d01-97bd-4370b5326610"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "1e26322a6ae7484daa9cdb514369dac8",
            "99a28e3c573842f8ae59ef66b11ce81a",
            "006a53e7883c46afa1f981480b6e5613",
            "e700154ff3c841cd9bc19b9d34a4adac",
            "3a50289bb8294798b7730b57e18ea23d",
            "96235767c57c42d1aaa39ab72000ec0e",
            "1ddbbe352c0742daa10be2cd84e30f02",
            "6e80c18a07dd44ac9338c6503852d429",
            "d0069cbc123846399eeb434e86720dcf",
            "64d770802f4e456cb833434a0e62e4b7",
            "968b230cb14e43a0b4b57ead0501e451",
            "0799e73f1f734c5e9ca4e820dc2b2e3e",
            "e506076329594e118aed0b326aa9e9fc",
            "a0ea58cf56754d498d5a2fd7a4d5a184",
            "b19c7606aa3b4a51ab3e8ddf42222c0b",
            "5aefce8caf2d4b59ba391b777ea7d2d3",
            "6b12554e48d7424bb1629bf83c174599",
            "0f2b482286414586a3249df01cf742d2",
            "d60c9c62f6f04df49d07cba24af09d5e",
            "c09c069ce385414780207435a38c49b3",
            "c994eb80935a4b869c2b4e44e2371a0a",
            "d04c7a791f4543e79c97ee4d029412a7"
          ]
        },
        "id": "210b17dc-5dcf-430d-89f8-ab6290fbc05f",
        "outputId": "333de90f-ac2a-400c-e794-19d13a6be526"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e26322a6ae7484daa9cdb514369dac8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/546 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0799e73f1f734c5e9ca4e820dc2b2e3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import logging\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# config.json 에 입력된 architecture 에 따라 베이스 모델 설정\n",
        "BASE_MODELS = {\n",
        "    \"BertForSequenceClassification\": BertForSequenceClassification,\n",
        "    \"AutoModel\": AutoModel,\n",
        "    \"ElectraForSequenceClassification\": ElectraForSequenceClassification,\n",
        "    \"AlbertForSequenceClassification\": AlbertForSequenceClassification,\n",
        "    \"RobertaForSequenceClassification\": RobertaForSequenceClassification\n",
        "}\n",
        "\n",
        "model = BASE_MODELS[config.model.architecture].from_pretrained(config.model.pretrained_model, num_labels = config.train.num_classes)\n",
        "# print(model)"
      ],
      "id": "210b17dc-5dcf-430d-89f8-ab6290fbc05f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ce1b90a-a033-4005-af89-a2f930882a7d"
      },
      "outputs": [],
      "source": [
        "# # 학습을 재개할 시 config 파일의 resume_weight_dir를 설정해주세요\n",
        "# if config.train.resume :\n",
        "#     checkpoint = torch.load(config.train.resume_weight_dir)\n",
        "#     model.load_state_dict(checkpoint['model'])"
      ],
      "id": "2ce1b90a-a033-4005-af89-a2f930882a7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb5679e8-94a3-4f65-bcbe-adbf7c033896"
      },
      "source": [
        "# 6. Optimizer"
      ],
      "id": "cb5679e8-94a3-4f65-bcbe-adbf7c033896"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25093b87-6432-4419-aa7a-346e96c339a0"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(model.parameters(), lr=config.train.learning_rate, eps=config.train.adam_epsilon)\n",
        "\n",
        "total_steps = len(train_dataloader) * config.train.num_epochs \n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * config.train.warmup_proportion), \n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "# lr_scheduler_test\n",
        "# lr_scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * config.train.warmup_proportion), num_training_steps=total_steps)\n",
        "# lr_scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * config.train.warmup_proportion))\n"
      ],
      "id": "25093b87-6432-4419-aa7a-346e96c339a0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4fba02f-b593-42e2-ba7c-e3d9a70018b9"
      },
      "source": [
        "# 7. Metric"
      ],
      "id": "c4fba02f-b593-42e2-ba7c-e3d9a70018b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0de7e3dc-8575-43e8-bd9e-f708439b8f4f"
      },
      "source": [
        "- [evaluate 라이브러리 document](https://pypi.org/project/evaluate/)\n",
        "- [각 metric 사용법](https://huggingface.co/evaluate-metric?sort_spaces=alphabetical#spaces)"
      ],
      "id": "0de7e3dc-8575-43e8-bd9e-f708439b8f4f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8322e28-86fd-44b9-adb8-9e38416dc3fc"
      },
      "outputs": [],
      "source": [
        "# 사용 가능한 metric 리스트를 보려면 아래를 주석 해제하여 확인하여 config 파일을 수정하여 다시 불러오세요.\n",
        "# evaluate.list_evaluation_modules()\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    metric_fn = evaluate.load(config.train.metric)\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    if config.train.metric=='f1':\n",
        "        score = metric_fn.compute(predictions=predictions, references=labels, average='macro')\n",
        "    else:\n",
        "        score = metric_fn.compute(predictions=predictions, references=labels)\n",
        "    return score"
      ],
      "id": "a8322e28-86fd-44b9-adb8-9e38416dc3fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd3feba6-2fb9-46bf-8a64-04bc0219b8c0"
      },
      "source": [
        "# 8. Early stopper"
      ],
      "id": "cd3feba6-2fb9-46bf-8a64-04bc0219b8c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06b71842-1b9f-4b57-8273-efe8c713c52d",
        "outputId": "b57b2b44-8d7f-4fe8-cb9a-f4d6c1491048"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:train:Initiated ealry stopper, mode: min, best score: inf, patience: 5\n"
          ]
        }
      ],
      "source": [
        "from modules.earlystoppers import EarlyStopper\n",
        "\n",
        "early_stopper = EarlyStopper(patience=config.train.early_stopping_patience,\n",
        "                             mode='min',\n",
        "                             logger=logger)"
      ],
      "id": "06b71842-1b9f-4b57-8273-efe8c713c52d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a2eaa25-3368-4748-96bf-495b0b289fad"
      },
      "source": [
        "# 9. Recorder"
      ],
      "id": "6a2eaa25-3368-4748-96bf-495b0b289fad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db4b3ed5-b323-4c82-bfa3-d3e4f1d5f6e2"
      },
      "outputs": [],
      "source": [
        "from modules.recorders import Recorder\n",
        "\n",
        "recorder = Recorder(record_dir=RECORDER_DIR,\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    scheduler=None,\n",
        "                    amp=None,\n",
        "                    logger=logger)"
      ],
      "id": "db4b3ed5-b323-4c82-bfa3-d3e4f1d5f6e2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "b12ffc7e-7159-4082-91ce-b5d85192d3be",
        "outputId": "c33977cf-7d73-4ea4-d34a-1c3c9f762fe6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find shopping_conversation.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Shopping/results/train/20221019_180402/wandb/run-20221208_012211-ns6ckx66</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cheche7/shopping_conversation/runs/ns6ckx66\" target=\"_blank\">vocal-sponge-51</a></strong> to <a href=\"https://wandb.ai/cheche7/shopping_conversation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Wandb\n",
        "# Wandb 사용법은 11월 21일 곽대훈 멘토님의 강의를 참고하세요!\n",
        "if config.train.wandb:\n",
        "    \n",
        "    wandb_project_serial = 'shopping_conversation'\n",
        "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = wandb_project_serial\n",
        "    wandb_username = 'cheche7' # 각자의 계정으로 수정하세요.\n",
        "    wandb.init(project=wandb_project_serial, dir=RECORDER_DIR, entity=wandb_username)\n",
        "    wandb.run.name = train_serial\n",
        "    wandb.config.update(config)\n",
        "    wandb.watch(model)\n"
      ],
      "id": "b12ffc7e-7159-4082-91ce-b5d85192d3be"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1c5b3a8-a307-4a12-ab53-e1f2a7b4ac57"
      },
      "source": [
        "# 10. Trainer Class 정의\n",
        "\n",
        "### 학습 파라미터 설정\n",
        "\n",
        "- [transformers Trainer 설명](https://huggingface.co/docs/transformers/main_classes/trainer)\n",
        "- [transformers TrainingArguments 파라미터 설명](https://huggingface.co/docs/transformers/v4.23.1/en/main_classes/trainer#transformers.TrainingArguments) : Training Arguments 파라미터 설명이 기술되어 있으니 참고하시어 각 파라미터가 의미하는 바를 알아보고 조정, 혹은 추가해보세요."
      ],
      "id": "a1c5b3a8-a307-4a12-ab53-e1f2a7b4ac57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5069a877-a78e-4f1b-b7ef-d0fe7b0341d5"
      },
      "outputs": [],
      "source": [
        "# transformers에서 Trainer를 불러와서 학습에 사용할텐데, 그때 사용할 파라미터들을 미리 지정해둔다\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= RECORDER_DIR,  # output directory\n",
        "    num_train_epochs=config.train.num_epochs,  # total number of training epochs\n",
        "    resume_from_checkpoint = config.train.resume_weight_dir,\n",
        "    per_device_train_batch_size=config.train.train_batch_size,  # batch size per device during training\n",
        "    per_device_eval_batch_size=config.train.eval_batch_size,  # batch size for evaluation\n",
        "    learning_rate = config.train.learning_rate,\n",
        "    warmup_ratio = config.train.warmup_proportion,\n",
        "    weight_decay=config.train.weight_decay,\n",
        "    logging_strategy = config.train.logging_strategy,\n",
        "    # logging_steps=config.train.logging_steps, # valid when logging_strategy ='steps'\n",
        "    save_strategy=config.train.save_strategy,\n",
        "    # save_steps=config.train.save_steps, # valid when save_strategy ='steps'\n",
        "    # eval_steps=config.train.eval_steps, # valid when save_strategy ='steps'\n",
        "    do_train=True, # Perform training\n",
        "    do_eval=True, # Perform evaluation\n",
        "    evaluation_strategy = config.train.evaluation_strategy, # evalute after each epoch\n",
        "    gradient_accumulation_steps = 64,  # total number of steps before back propagation\n",
        "    fp16 = config.train.fp16, # Use mixed precision\n",
        "    run_name = train_serial, # experiment name, typically used for wandb\n",
        "    report_to=\"wandb\",  # disable wandb\n",
        "    load_best_model_at_end = True,\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=3,\n",
        "    seed= config.train.seed  # Seed for experiment reproducibility\n",
        ")"
      ],
      "id": "5069a877-a78e-4f1b-b7ef-d0fe7b0341d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e918cf04-3ebf-407b-9129-a9a7e38bbdb5"
      },
      "source": [
        "## 학습 "
      ],
      "id": "e918cf04-3ebf-407b-9129-a9a7e38bbdb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c7a57f5-d755-4446-854e-1db597ff6186"
      },
      "outputs": [],
      "source": [
        "class Run:\n",
        "\n",
        "    def __init__(self, trainer, tokenizer, training_args, test=None, submission_name = None):\n",
        "        self.trainer = trainer\n",
        "        self.tokenizer = tokenizer\n",
        "        self.training_args = training_args\n",
        "        self.test = test\n",
        "        self.submission_name = submission_name\n",
        "\n",
        "    def __call__(self):\n",
        "        if self.training_args.do_train:\n",
        "            self.train()\n",
        "\n",
        "        if self.training_args.do_eval:\n",
        "            self.validate()\n",
        "\n",
        "        if self.training_args.do_predict and self.test is not None:\n",
        "            self.predict()\n",
        "\n",
        "    def train(self):\n",
        "        self.trainer.train()\n",
        "        self.trainer.save_model()\n",
        "        if self.trainer.is_world_process_zero():\n",
        "            self.tokenizer.save_pretrained(RECORDER_DIR)\n",
        "\n",
        "    def validate(self):\n",
        "        logger.info(\"*** Evaluate ***\")\n",
        "        result = self.trainer.evaluate()\n",
        "        output_eval_file = os.path.join(RECORDER_DIR, \"eval_results.txt\")\n",
        "        if self.trainer.is_world_process_zero():\n",
        "            with open(output_eval_file, \"w\") as writer:\n",
        "                logger.info(\"***** Eval results *****\")\n",
        "                for key, value in result.items():\n",
        "                    logger.info(\"%s = %s\", key, value)\n",
        "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "        logger.info(\"Validation set result : {}\".format(result))\n",
        "\n",
        "    # 추론 함수\n",
        "    def predict(self):\n",
        "        logger.info(\"*** Test ***\")\n",
        "        predictions = self.trainer.predict(test_dataset=self.test)\n",
        "        test_df['speechAct'] = self.prediction(predictions.predictions)\n",
        "        test_df.to_csv(self.submission_name, index=False)\n",
        "        test_df.sort_values(by='sentence_id', ascending=True)\n",
        "        print(\"Submission file saved as :\", self.submission_name)\n",
        "\n",
        "    def prediction(self,logit):\n",
        "        labels = np.argmax(logit, axis=1)\n",
        "        return list(map(lambda x: encoding2label[x], labels))"
      ],
      "id": "5c7a57f5-d755-4446-854e-1db597ff6186"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41713ea4-857c-4b92-bea5-3b71acffcbe5"
      },
      "source": [
        "# 11. Trainer 선언"
      ],
      "id": "41713ea4-857c-4b92-bea5-3b71acffcbe5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98c42f52-cebe-4e5b-be0f-0bd454eae118",
        "outputId": "7eb191d8-14d2-4897-d62c-a679f1b65a82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "# Trainer\n",
        "from transformers import Trainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "# Set trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "callbacks=[EarlyStoppingCallback(early_stopping_patience=config.train.early_stopping_patience)]\n",
        "\n",
        ")\n",
        "\n",
        "# Set runner\n",
        "train = Run(\n",
        "    training_args=training_args,\n",
        "    trainer=trainer,\n",
        "    tokenizer=TOKENIZER,\n",
        "    )"
      ],
      "id": "98c42f52-cebe-4e5b-be0f-0bd454eae118"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "249c24f0-e0a4-40cd-aabb-17c30ae48e29"
      },
      "source": [
        "# 12. 학습"
      ],
      "id": "249c24f0-e0a4-40cd-aabb-17c30ae48e29"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "1f2713cd92e84429af08c66b78825760"
          ]
        },
        "id": "5a77bb51-345b-4a39-b840-014a475a2d49",
        "outputId": "c9eb93da-c0ee-4c03-bb69-e9ac96afec0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 151826\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2048\n",
            "  Gradient Accumulation steps = 64\n",
            "  Total optimization steps = 74\n",
            "  Number of trainable parameters = 110628878\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 37957\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9466, 'learning_rate': 0.0, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f2713cd92e84429af08c66b78825760",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-74\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6119049191474915, 'eval_f1': 0.4359302576770813, 'eval_runtime': 82.389, 'eval_samples_per_second': 460.705, 'eval_steps_per_second': 14.407, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-74/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-74/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-74 (score: 0.6119049191474915).\n",
            "Saving model checkpoint to /content/drive/MyDrive/Shopping/results/train/20221019_180402\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 1034.7582, 'train_samples_per_second': 146.726, 'train_steps_per_second': 0.072, 'train_loss': 0.9465766081938872, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/special_tokens_map.json\n",
            "INFO:train:*** Evaluate ***\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 37957\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6119049191474915, 'eval_f1': 0.4359302576770813, 'eval_runtime': 82.3924, 'eval_samples_per_second': 460.686, 'eval_steps_per_second': 14.407, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:train:***** Eval results *****\n",
            "INFO:train:eval_loss = 0.6119049191474915\n",
            "INFO:train:eval_f1 = 0.4359302576770813\n",
            "INFO:train:eval_runtime = 82.3924\n",
            "INFO:train:eval_samples_per_second = 460.686\n",
            "INFO:train:eval_steps_per_second = 14.407\n",
            "INFO:train:epoch = 1.0\n",
            "INFO:train:Validation set result : {'eval_loss': 0.6119049191474915, 'eval_f1': 0.4359302576770813, 'eval_runtime': 82.3924, 'eval_samples_per_second': 460.686, 'eval_steps_per_second': 14.407, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "train()"
      ],
      "id": "5a77bb51-345b-4a39-b840-014a475a2d49"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "285debfc-3ce7-4390-a18d-80f201db00c6"
      },
      "source": [
        "# 13. 추론 \n",
        "### 추론 config 설정"
      ],
      "id": "285debfc-3ce7-4390-a18d-80f201db00c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5563f210-e27e-43d9-8976-db11c2835530"
      },
      "outputs": [],
      "source": [
        "# Load config\n",
        "predict_config_path = os.path.join(PROJECT_DIR, 'baseline', 'config', 'predict.yaml')\n",
        "predict_config = OmegaConf.load(predict_config_path)"
      ],
      "id": "5563f210-e27e-43d9-8976-db11c2835530"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48db8e84-12a5-46e8-a2b9-145de1efae81"
      },
      "source": [
        "### 추론을 로깅할 디렉토리 생성"
      ],
      "id": "48db8e84-12a5-46e8-a2b9-145de1efae81"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "19554fa0-94dc-429f-a746-07ea7c5bbf74"
      },
      "outputs": [],
      "source": [
        "# Serial\n",
        "if predict_config['predict']['train_serial'] is None:\n",
        "    train_serial = os.path.basename(RECORDER_DIR)\n",
        "else:\n",
        "    train_serial = predict_config['predict']['train_serial']\n",
        "    \n",
        "\n",
        "# Predict directory\n",
        "PREDICT_DIR = os.path.join(RECORDER_DIR, 'predict')\n",
        "os.makedirs(PREDICT_DIR, exist_ok=True)"
      ],
      "id": "19554fa0-94dc-429f-a746-07ea7c5bbf74"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bd89362-3398-4012-a0e9-fb2857ec3936"
      },
      "source": [
        "### 데이터 경로 지정"
      ],
      "id": "3bd89362-3398-4012-a0e9-fb2857ec3936"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3185cfc6-836d-4bf9-843b-0536e97dc19e"
      },
      "outputs": [],
      "source": [
        "# Data Directory\n",
        "DATA_DIR = predict_config['predict']['dataset_path']"
      ],
      "id": "3185cfc6-836d-4bf9-843b-0536e97dc19e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33acd73e-f0ab-42d7-b2a1-33945eeaf097"
      },
      "source": [
        "### 테스트 데이터셋 및 데이터 로더 선언\n"
      ],
      "id": "33acd73e-f0ab-42d7-b2a1-33945eeaf097"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3339dd2d-8afd-4743-bb0e-dff6acfa86f7",
        "outputId": "e52bb91c-4bcd-4e97-f726-d6fc88cd3895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test dataset:  20520\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "test_df = make_df(TEST_DIR, test=True)\n",
        "test_dataset = CustomDataset(test_df, TOKENIZER, config.train.max_seq_len, 'test')\n",
        "print(\"Test dataset: \", len(test_dataset))\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                            batch_size=predict_config.predict.batch_size,\n",
        "                            num_workers=predict_config.predict.num_workers,\n",
        "                            shuffle=False,\n",
        "                            pin_memory=True,\n",
        "                            drop_last=False)"
      ],
      "id": "3339dd2d-8afd-4743-bb0e-dff6acfa86f7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f05fa197-1a67-4c44-b2f0-8a68ae5e2901",
        "outputId": "217fe43b-1317-445c-82a8-24eac90b10aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-01675ecd-fd6e-4e25-b9eb-a00da7213c69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0901.txt-0</td>\n",
              "      <td>A</td>\n",
              "      <td>반갑습니다 즐거운 쇼핑 #@소속#입니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_0901.txt-1</td>\n",
              "      <td>A</td>\n",
              "      <td>어떤 문의가 있으신가요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_0901.txt-2</td>\n",
              "      <td>B</td>\n",
              "      <td>네 궁금한 게 있어요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_0901.txt-3</td>\n",
              "      <td>B</td>\n",
              "      <td>쿠폰과 이벤트 코드는 뭐가 다르죠</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_0901.txt-4</td>\n",
              "      <td>A</td>\n",
              "      <td>이벤트 코드는 다양한 수단으로 고객님께 전달됩니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20515</th>\n",
              "      <td>test_0980.txt-12</td>\n",
              "      <td>A</td>\n",
              "      <td>아무래도 그런 걸 구입하시는 게 금액이 더 저렴합니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20516</th>\n",
              "      <td>test_0980.txt-13</td>\n",
              "      <td>B</td>\n",
              "      <td>그럼 마트가서 사야겠네요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20517</th>\n",
              "      <td>test_0980.txt-14</td>\n",
              "      <td>A</td>\n",
              "      <td>네 저도 같은 제품 사용하고 있는데 다른 제품 사서 쓰고 있거든요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20518</th>\n",
              "      <td>test_0980.txt-15</td>\n",
              "      <td>B</td>\n",
              "      <td>그러세요 저도 그렇게 해야겠네요 감사합니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20519</th>\n",
              "      <td>test_0980.txt-16</td>\n",
              "      <td>A</td>\n",
              "      <td>네 감사합니다 고객님 좋은 하루 되십시오</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20520 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01675ecd-fd6e-4e25-b9eb-a00da7213c69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01675ecd-fd6e-4e25-b9eb-a00da7213c69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01675ecd-fd6e-4e25-b9eb-a00da7213c69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            sentence_id speaker                                  text\n",
              "0       test_0901.txt-0       A                 반갑습니다 즐거운 쇼핑 #@소속#입니다\n",
              "1       test_0901.txt-1       A                          어떤 문의가 있으신가요\n",
              "2       test_0901.txt-2       B                           네 궁금한 게 있어요\n",
              "3       test_0901.txt-3       B                    쿠폰과 이벤트 코드는 뭐가 다르죠\n",
              "4       test_0901.txt-4       A           이벤트 코드는 다양한 수단으로 고객님께 전달됩니다\n",
              "...                 ...     ...                                   ...\n",
              "20515  test_0980.txt-12       A         아무래도 그런 걸 구입하시는 게 금액이 더 저렴합니다\n",
              "20516  test_0980.txt-13       B                         그럼 마트가서 사야겠네요\n",
              "20517  test_0980.txt-14       A  네 저도 같은 제품 사용하고 있는데 다른 제품 사서 쓰고 있거든요\n",
              "20518  test_0980.txt-15       B               그러세요 저도 그렇게 해야겠네요 감사합니다\n",
              "20519  test_0980.txt-16       A                네 감사합니다 고객님 좋은 하루 되십시오\n",
              "\n",
              "[20520 rows x 3 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ],
      "id": "f05fa197-1a67-4c44-b2f0-8a68ae5e2901"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "25426e0d-bae3-43d2-b9a6-30e3c30aa041",
        "outputId": "91e41a3e-608e-4e13-8176-e4bcbdfcea96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file /content/drive/MyDrive/Shopping/results/train/20221019_180402/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"klue/roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Shopping/results/train/20221019_180402/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Shopping/results/train/20221019_180402.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "model = BASE_MODELS[config.model.architecture].from_pretrained(RECORDER_DIR)\n",
        "\n",
        "predicting_args = TrainingArguments(\n",
        "        run_name=train_serial,\n",
        "        disable_tqdm=False,\n",
        "        per_device_eval_batch_size = predict_config.predict.batch_size,\n",
        "        fp16=config.train.fp16,\n",
        "        gradient_accumulation_steps=64,\n",
        "        do_train=False,\n",
        "        do_eval=False,\n",
        "        do_predict=True,\n",
        "        output_dir='.',\n",
        "    )\n",
        "\n",
        "trainer_prediction = Trainer(\n",
        "    model= model,\n",
        "    args=predicting_args\n",
        ")\n",
        "\n",
        "predict = Run(\n",
        "    training_args=predicting_args,\n",
        "    trainer=trainer_prediction,\n",
        "    tokenizer=TOKENIZER,\n",
        "    test=test_dataset,\n",
        "    submission_name = predict_config.predict.submission_name\n",
        "    )"
      ],
      "id": "25426e0d-bae3-43d2-b9a6-30e3c30aa041"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7128ec25-87df-443c-9421-fccbb069b8c0"
      },
      "source": [
        "## 추론"
      ],
      "id": "7128ec25-87df-443c-9421-fccbb069b8c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bd8c58b1-b713-40b1-877f-04a04a164a7e",
        "outputId": "5671fc7f-ae72-408d-d680-1707d6fb91b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:train:*** Test ***\n",
            "***** Running Prediction *****\n",
            "  Num examples = 20520\n",
            "  Batch size = 1\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file saved as : submission.csv\n"
          ]
        }
      ],
      "source": [
        "predict()"
      ],
      "id": "bd8c58b1-b713-40b1-877f-04a04a164a7e"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "79b2fe59-0197-44ed-8ba7-68c988b2747f",
        "7ce4062a-7030-4a06-9ec1-985a9e7bd49e",
        "dIiEaoZLN-qY",
        "d3522ede-dcec-4a26-8cc1-b7e03ad5faf9",
        "abca2710-8f81-42f8-aeaf-6d6ea8b56dce",
        "48db8e84-12a5-46e8-a2b9-145de1efae81",
        "3bd89362-3398-4012-a0e9-fb2857ec3936",
        "33acd73e-f0ab-42d7-b2a1-33945eeaf097"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "006a53e7883c46afa1f981480b6e5613": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e80c18a07dd44ac9338c6503852d429",
            "max": 546,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0069cbc123846399eeb434e86720dcf",
            "value": 546
          }
        },
        "0799e73f1f734c5e9ca4e820dc2b2e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e506076329594e118aed0b326aa9e9fc",
              "IPY_MODEL_a0ea58cf56754d498d5a2fd7a4d5a184",
              "IPY_MODEL_b19c7606aa3b4a51ab3e8ddf42222c0b"
            ],
            "layout": "IPY_MODEL_5aefce8caf2d4b59ba391b777ea7d2d3"
          }
        },
        "0f2b482286414586a3249df01cf742d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ddbbe352c0742daa10be2cd84e30f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e26322a6ae7484daa9cdb514369dac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99a28e3c573842f8ae59ef66b11ce81a",
              "IPY_MODEL_006a53e7883c46afa1f981480b6e5613",
              "IPY_MODEL_e700154ff3c841cd9bc19b9d34a4adac"
            ],
            "layout": "IPY_MODEL_3a50289bb8294798b7730b57e18ea23d"
          }
        },
        "3a50289bb8294798b7730b57e18ea23d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aefce8caf2d4b59ba391b777ea7d2d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64d770802f4e456cb833434a0e62e4b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b12554e48d7424bb1629bf83c174599": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e80c18a07dd44ac9338c6503852d429": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96235767c57c42d1aaa39ab72000ec0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "968b230cb14e43a0b4b57ead0501e451": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99a28e3c573842f8ae59ef66b11ce81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96235767c57c42d1aaa39ab72000ec0e",
            "placeholder": "​",
            "style": "IPY_MODEL_1ddbbe352c0742daa10be2cd84e30f02",
            "value": "Downloading: 100%"
          }
        },
        "a0ea58cf56754d498d5a2fd7a4d5a184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60c9c62f6f04df49d07cba24af09d5e",
            "max": 442694866,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c09c069ce385414780207435a38c49b3",
            "value": 442694866
          }
        },
        "b19c7606aa3b4a51ab3e8ddf42222c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c994eb80935a4b869c2b4e44e2371a0a",
            "placeholder": "​",
            "style": "IPY_MODEL_d04c7a791f4543e79c97ee4d029412a7",
            "value": " 443M/443M [00:13&lt;00:00, 39.6MB/s]"
          }
        },
        "c09c069ce385414780207435a38c49b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c994eb80935a4b869c2b4e44e2371a0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0069cbc123846399eeb434e86720dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d04c7a791f4543e79c97ee4d029412a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d60c9c62f6f04df49d07cba24af09d5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e506076329594e118aed0b326aa9e9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b12554e48d7424bb1629bf83c174599",
            "placeholder": "​",
            "style": "IPY_MODEL_0f2b482286414586a3249df01cf742d2",
            "value": "Downloading: 100%"
          }
        },
        "e700154ff3c841cd9bc19b9d34a4adac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64d770802f4e456cb833434a0e62e4b7",
            "placeholder": "​",
            "style": "IPY_MODEL_968b230cb14e43a0b4b57ead0501e451",
            "value": " 546/546 [00:00&lt;00:00, 10.7kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}